rook-ceph-cluster:

  toolbox:
    enabled: true

  monitoring:
    enabled: true
    createPrometheusRules: true

  ingress:
    dashboard:
      host:
        name: ceph.mobrockers.com
      tls:
      - hosts:
        - ceph.mobrockers.com

  cephClusterSpec:
    cephVersion:
      image: quay.io/ceph/ceph:v19.2.3

    network:
      connections:
        encryption:
          enabled: true
        compression:
          enabled: true
        requireMsgr2: true
      provider: host
      addressRanges:
        public: ['10.0.102.0/24']
        cluster: ['10.0.104.0/24']
      
    cephConfig:
      osd:
        osd_mclock_profile: "high_recovery_ops"
      mgr:
        mgr/dashboard/standby_behaviour: 'error'
        mgr/dashboard/FEATURE_TOGGLE_NFS: 'false'
        mgr/dashboard/FEATURE_TOGGLE_ISCSI: 'false'
        mgr/dashboard/FEATURE_TOGGLE_MIRRORING: 'false'

    # cephConfigFromSecret:
    #   mgr:
    #     mgr/dashboard/GRAFANA_API_PASSWORD:
    #       name: grafana-api-credential # name of the Kubernetes secret
    #       key: password

    dashboard:
      ssl: false
      prometheusEndpoint: http://kube-prometheus-stack-prometheus.prometheus.svc:9090

    csi:
      readAffinity:
        enabled: true

    placement:
      mon:
        topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: ScheduleAnyway
      mgr:
        topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: ScheduleAnyway
    mon:
      count: 3

    mgr:
      count: 2
      modules:
      - name: pg_autoscaler
        enabled: true
      - name: insights
        enabled: true
      - name: rgw
        enabled: true
      - name: rook
        enabled: true

    storage:
      useAllNodes: false
      useAllDevices: false
      allowDeviceClassUpdate: true
      nodes:
      - name: talos-worker-1
        devices:
        - name: /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_drive-scsi1
          deviceClass: nvme
        - name: /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_drive-scsi2
          deviceClass: nvme
        - name: /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_drive-scsi3
          deviceClass: hdd
        - name: /dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_drive-scsi4
          deviceClass: hdd
      - name: talos-worker-2
        devices:
        - name: /dev/disk/by-id/nvme-Lexar_SSD_NM710_2TB_PMT466R005385P2703
          deviceClass: nvme
      - name: talos-worker-3
        devices:
        - name: /dev/disk/by-id/nvme-Lexar_SSD_NM710_2TB_PM40364102031P2703
          deviceClass: nvme
      - name: talos-worker-4
        devices:
        - name: /dev/disk/by-id/nvme-Lexar_SSD_NM710_2TB_PM40364101942P2703
          deviceClass: nvme
      - name: talos-worker-5
        devices:
        - name: /dev/disk/by-id/nvme-Lexar_SSD_NM710_2TB_PMT466R009894P2703
          deviceClass: nvme

    resources:
      mgr:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          memory: 1Gi
      mon:
        requests:
          cpu: 1000m
          memory: 1Gi
        limits:
          memory: 2Gi
      osd:
        requests:
          cpu: 500m
          memory: 3Gi
        limits:
          memory: 5Gi
      prepareosd:
        requests:
          cpu: 500m
          memory: 50Mi
      mgr-sidecar:
        requests:
          cpu: 100m
          memory: 40Mi
        limits:
          memory: 100Mi
      crashcollector:
        requests:
          cpu: 10m
          memory: 50Mi
        limits:
          memory: 100Mi
      logcollector:
        requests:
          cpu: 10m
          memory: 10Mi
        limits:
          memory: 100Mi
      cleanup:
        requests:
          cpu: 500m
          memory: 100Mi
        limits:
          memory: 1Gi
      exporter:
        requests:
          cpu: 50m
          memory: 50Mi
        limits:
          memory: 128Mi
